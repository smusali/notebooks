{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-info\"><b></b>\n",
        "<h1><center> <font color='black'> Homework 05</font></center></h1>\n",
        "<h2><center> <font color='black'> A/B Testing & Uplift modelling</font></center></h2>    \n",
        "<h2><center> <font color='black'> MTAT.03.319 - Business Data Analytics</font></center></h2>\n",
        "<h2><center> <font color='black'> University of Tartu - Spring 2023</font></center></h2>\n",
        "</div>"
      ],
      "metadata": {
        "id": "noghGtl4u71J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework instructions\n",
        "\n",
        "- Please provide the names and student IDs of the team-members (Maximum 2 person) in the field \"Team mates\" below. If you are not working in a team please insert only your name and student ID.\n",
        "\n",
        "- Please provide code where ever applicable.\n",
        "\n",
        "- The accepted submission format is .ipynb file. If you are sharing Colab link, make sure that the privacy settings for the file is public so we can access your code. \n",
        "\n",
        "- The submission will automatically close on <font color='red'>**30 April at 23:59**</font>, so please make sure to submit before the deadline. \n",
        "\n",
        "- ONLY one of the teammates should submit the homework and in the submission description the other person's Name and Student ID must be entered. We will grade the homework and the marks and feedback is applied for both the team members. So please communicate with your team member about marks and feedback if you are submit the homework.\n",
        "\n",
        "- If a question is not clear, please ask us in Moodle ONLY. \n",
        "\n",
        "- After you have finished solving the Homework, please restart the Kernel and run all the cells to check if there is any persisting issues. \n",
        "\n",
        "- Plagiarism is <font color='red'>**PROHIBITED**</font>. Any form of plagiarism will be dealt according to the university policy (https://ut.ee/en/content/academic-fraud).\n",
        "\n",
        "- <font color='red'>**DO NOT CHANGE THE TEMPLATE**</font>\n",
        "\n",
        "- <font color='red'>**Restart the Kernel and Run all the cells once again after you are done.**</font>\n",
        "This will ensure that all the cells run without error. You will find an option in the top menu bar under Kernel tab. "
      ],
      "metadata": {
        "id": "K_RWhzhrvDO6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyvLCyxpAGW9"
      },
      "source": [
        "**<h2><font color='red'>Team mates:</font></h2>**\n",
        "\n",
        "\n",
        "<font color='red'>Name: </font> Samir Musali &emsp; <font color='red'>Student ID: </font> C29810"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5egu0aiAGW9"
      },
      "source": [
        "### The homework is divided into two sections and the points are distributed as below:\n",
        "<pre>\n",
        "- A/B Testing               -> 5.5 points\n",
        "- Uplift modeling           -> 5.5 points\n",
        "________________________________________________\n",
        "Total                       -> 11.0 points\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brw7EC-FAGW-"
      },
      "source": [
        "# 1. A/B Testing (5.5 points)\n",
        "\n",
        "\n",
        "**1.1 Use `AB_clicks.csv` data and find whether Learn, Help, and Services versions of the page compared to the Interact have significantly more (or less) clicks. Justify the choice of the performed tests and interpret the result of the test. (1.5 points)** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsrJ_BtaAGW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ba4fbb-305c-48cf-c769-5bb4e86bf164"
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Load the data into a pandas DataFrame, skipping any lines with errors\n",
        "data = pd.read_csv('AB_clicks.csv', delimiter='\\t')\n",
        "\n",
        "# Extract the click data for Interact version\n",
        "interact_clicks = data[data['Version'] == 'Interact']['No_clicks']\n",
        "\n",
        "# Extract the click data for Learn version and perform the ANOVA test\n",
        "learn_clicks = data[data['Version'] == 'Learn']['No_clicks']\n",
        "f_statistic_learn, p_value_learn = f_oneway(interact_clicks, learn_clicks)\n",
        "print('=====')\n",
        "print('F statistic for Learn:', f_statistic_learn)\n",
        "print('p-value for Learn:', p_value_learn)\n",
        "print('=====')\n",
        "\n",
        "# Extract the click data for Help version and perform the ANOVA test\n",
        "help_clicks = data[data['Version'] == 'Help']['No_clicks']\n",
        "f_statistic_help, p_value_help = f_oneway(interact_clicks, help_clicks)\n",
        "print('=====')\n",
        "print('F statistic for Help:', f_statistic_help)\n",
        "print('p-value for Help:', p_value_help)\n",
        "print('=====')\n",
        "\n",
        "# Extract the click data for Services version and perform the ANOVA test\n",
        "services_clicks = data[data['Version'] == 'Services']['No_clicks']\n",
        "f_statistic_services, p_value_services = f_oneway(interact_clicks, services_clicks)\n",
        "print('=====')\n",
        "print('F statistic for Services:', f_statistic_services)\n",
        "print('p-value for Services:', p_value_services)\n",
        "print('=====')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====\n",
            "F statistic for Learn: 1.0480354270900327\n",
            "p-value for Learn: 0.3078759180594482\n",
            "=====\n",
            "=====\n",
            "F statistic for Help: 0.7133607164859326\n",
            "p-value for Help: 0.39995700324796557\n",
            "=====\n",
            "=====\n",
            "F statistic for Services: 1.0426424596354409\n",
            "p-value for Services: 0.30926185388653943\n",
            "=====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mrP7tZqAGW_"
      },
      "source": [
        "\n",
        "**1.2 Use two different methods to test the normality of two different versions of your choice (Connect, Help, Services,..) (2.0 points)**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRsTOYpcAGW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8d7056-9e83-40ac-c3bb-353aa5ba3618"
      },
      "source": [
        "from scipy.stats import shapiro, anderson\n",
        "\n",
        "# Extract the click data for Help and Learn versions\n",
        "help_clicks = data[data['Version'] == 'Help']['No_clicks']\n",
        "learn_clicks = data[data['Version'] == 'Learn']['No_clicks']\n",
        "\n",
        "# Test the normality of the Help clicks using Shapiro-Wilk test\n",
        "shapiro_stat_help, shapiro_p_help = shapiro(help_clicks)\n",
        "print('=====')\n",
        "print('Shapiro-Wilk test for Help clicks:')\n",
        "print('Statistic:', shapiro_stat_help)\n",
        "print('p-value:', shapiro_p_help)\n",
        "print('=====')\n",
        "\n",
        "# Test the normality of the Learn clicks using Anderson-Darling test\n",
        "anderson_stat_learn, anderson_critvals_learn, anderson_siglvl_learn = anderson(learn_clicks)\n",
        "print('=====')\n",
        "print('Anderson-Darling test for Learn clicks:')\n",
        "print('Statistic:', anderson_stat_learn)\n",
        "print('Critical values:', anderson_critvals_learn)\n",
        "print('Significance levels:', anderson_siglvl_learn)\n",
        "print('=====')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====\n",
            "Shapiro-Wilk test for Help clicks:\n",
            "Statistic: 0.32242465019226074\n",
            "p-value: 9.140807719304565e-15\n",
            "=====\n",
            "=====\n",
            "Anderson-Darling test for Learn clicks:\n",
            "Statistic: 15.69964300122372\n",
            "Critical values: [0.544 0.62  0.744 0.868 1.032]\n",
            "Significance levels: [15.  10.   5.   2.5  1. ]\n",
            "=====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7uphXYiAGW_"
      },
      "source": [
        "**1.3 Read about Multiple comparison problem read ([wikipedia](https://en.wikipedia.org/wiki/Multiple_comparisons_problem), [An Overview of Methods to Address the Multiple Comparison Problem](https://towardsdatascience.com/an-overview-of-methods-to-address-the-multiple-comparison-problem-310427b3ba92) or other resources). What is the problem and when we need to do something about it (describe briefly)? (1 points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaqQxLijAGXA"
      },
      "source": [
        "<font color='red'> **Answer:** The Multiple Comparison Problem (MCP) arises when multiple hypotheses are tested on the same data set, increasing the likelihood of making at least one type I error (rejecting a true null hypothesis). In other words, as the number of comparisons increases, the possibility of observing at least one significant result by chance alone also increases.\n",
        "When performing multiple hypothesis tests on the same data set, we must do something about the Multiple Comparison Problem (MCP). One common approach to address this problem is to adjust the significance level using a correction method such as the Bonferroni correction, which involves dividing the original significance level by the number of comparisons made. Another approach is to use a False Discovery Rate (FDR) correction, which controls the expected proportion of false discoveries among all discoveries.\n",
        "Ignoring the Multiple Comparison Problem (MCP) can result in false positive results, which can have serious consequences, especially in fields such as medicine and finance, where decisions based on statistical significance can impact people's lives and financial outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbdhsGiNAGXA"
      },
      "source": [
        "**1.4 Load the dataset classifier_results.csv. The dataset contains the following fields:** \n",
        "\n",
        "**Dataset** - 200 datasets retreived from [OpenML](https://www.openml.org/search?type=data) dataset directory.\n",
        "\n",
        "**Classifier** - 9 classifiers from scikit-learn\n",
        "\n",
        "**Accuracy** - The accuracy achieved after applying the classifier to the dataset\n",
        "\n",
        "\n",
        "**Is there a significant statistical difference between these classifiers ? If you were asked to continue your analysis with only a limited number of classifiers how many would you pick and why ? (1.0 points)** (Hint:You can use the orange package that was introduced in the practice session) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZU2dA-aAGXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39925c07-4436-423f-a5fd-8d3b03193e68"
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('classifier_results.csv')\n",
        "\n",
        "# Extract the accuracy data for each classifier\n",
        "classifiers = data['Classifier'].unique()\n",
        "accuracies = []\n",
        "for classifier in classifiers:\n",
        "    classifier_accuracies = data[data['Classifier'] == classifier]['Accuracy']\n",
        "    accuracies.append(classifier_accuracies)\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_statistic, p_value = f_oneway(*accuracies)\n",
        "\n",
        "# Print the ANOVA results\n",
        "print('F statistic:', f_statistic)\n",
        "print('p-value:', p_value)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F statistic: 0.6010799163946169\n",
            "p-value: 0.7759837327632423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSxbdc0iAGXB"
      },
      "source": [
        "<font color='red'> **Answer:** The ANOVA results show that the p-value is much more significant than the commonly used significance level of 0.05. This suggests that there is not enough evidence to reject the null hypothesis, which states that there is no significant difference between the means of the accuracy scores for the different classifiers. If we were asked to continue the analysis with only a limited number of classifiers, we could select the top performers based on their mean accuracy scores or some other performance metric. Alternatively, we could use a post hoc test like Tukey's HSD (Honestly Significant Difference) to determine which classifiers are significantly different. This would allow us to identify specific pairs of classifiers that are very different while controlling for the overall Type I error rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_iPNSLUAGXB"
      },
      "source": [
        "# 2. Uplift modelling (5.5 points)\n",
        "For this task we are going to use email_marketing.csv from [MineThatData](https://blog.minethatdata.com/2008/03/minethatdata-e-mail-analytics-and-data.html). The data was recorded from a two-weeks email campaign that included 64000 customers. Out of these customers:\n",
        "1. 1/3 were randomly chosen to receive an e-mail campaign featuring Mens merchandise.\n",
        "2. 1/3 were randomly chosen to receive an e-mail campaign featuring Womens merchandise.\n",
        "3. 1/3 were randomly chosen to not receive an e-mail campaign.\n",
        "\n",
        "The features in this dataset include:\n",
        "\n",
        "- Recency: Months since last purchase.\n",
        "- History: Actual dollar value spent in the past year.\n",
        "- Mens: 1/0 indicator, 1 = customer purchased Mens merchandise in the past year.\n",
        "- Womens: 1/0 indicator, 1 = customer purchased Womens merchandise in the past year.\n",
        "- Zip_Code: Classifies zip code as Urban, Suburban, or Rural.\n",
        "- Newbie: 1/0 indicator, 1 = New customer in the past twelve months.\n",
        "- Channel: Describes the channels the customer purchased from in the past year.\n",
        "- Segment: e-mail campaign  type that the customer received\n",
        "- Visit: 1/0 indicator, 1 = Customer visited website in the following two weeks.\n",
        "\n",
        "The last variable is realted to the evaluation if the campaign was effective or not.\n",
        "\n",
        "- Conversion: 1/0 indicator, 1 = Customer purchased merchandise in the following two weeks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.0 Load the dataset and provide description. (0.25 points)**"
      ],
      "metadata": {
        "id": "kfINatl_xuEa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asvMuGnFAGXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83cb670d-7dff-4d74-a66f-6b4a63766839"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas DataFrame\n",
        "df = pd.read_csv('email_marketing.csv')\n",
        "\n",
        "# Print the shape of the dataset (number of rows and columns)\n",
        "print(\"Shape of dataset:\", df.shape)\n",
        "\n",
        "# Print the first 5 rows of the dataset\n",
        "print(\"\\nFirst 5 rows of dataset:\\n\", df.head())\n",
        "\n",
        "# Print summary statistics for the numerical columns\n",
        "print(\"\\nSummary statistics for numerical columns:\\n\", df.describe())\n",
        "\n",
        "# Print the data types of the columns\n",
        "print(\"\\nData types of columns:\\n\", df.dtypes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of dataset: (64000, 12)\n",
            "\n",
            "First 5 rows of dataset:\n",
            "    recency history_segment  history  mens  womens   zip_code  newbie channel  \\\n",
            "0       10  2) $100 - $200   142.44     1       0  Surburban       0   Phone   \n",
            "1        6  3) $200 - $350   329.08     1       1      Rural       1     Web   \n",
            "2        7  2) $100 - $200   180.65     0       1  Surburban       1     Web   \n",
            "3        9  5) $500 - $750   675.83     1       0      Rural       1     Web   \n",
            "4        2    1) $0 - $100    45.34     1       0      Urban       0     Web   \n",
            "\n",
            "         segment  visit  conversion  spend  \n",
            "0  Womens E-Mail      0           0    0.0  \n",
            "1      No E-Mail      0           0    0.0  \n",
            "2  Womens E-Mail      0           0    0.0  \n",
            "3    Mens E-Mail      0           0    0.0  \n",
            "4  Womens E-Mail      0           0    0.0  \n",
            "\n",
            "Summary statistics for numerical columns:\n",
            "             recency       history          mens        womens        newbie  \\\n",
            "count  64000.000000  64000.000000  64000.000000  64000.000000  64000.000000   \n",
            "mean       5.763734    242.085656      0.551031      0.549719      0.502250   \n",
            "std        3.507592    256.158608      0.497393      0.497526      0.499999   \n",
            "min        1.000000     29.990000      0.000000      0.000000      0.000000   \n",
            "25%        2.000000     64.660000      0.000000      0.000000      0.000000   \n",
            "50%        6.000000    158.110000      1.000000      1.000000      1.000000   \n",
            "75%        9.000000    325.657500      1.000000      1.000000      1.000000   \n",
            "max       12.000000   3345.930000      1.000000      1.000000      1.000000   \n",
            "\n",
            "              visit    conversion         spend  \n",
            "count  64000.000000  64000.000000  64000.000000  \n",
            "mean       0.146781      0.009031      1.050908  \n",
            "std        0.353890      0.094604     15.036448  \n",
            "min        0.000000      0.000000      0.000000  \n",
            "25%        0.000000      0.000000      0.000000  \n",
            "50%        0.000000      0.000000      0.000000  \n",
            "75%        0.000000      0.000000      0.000000  \n",
            "max        1.000000      1.000000    499.000000  \n",
            "\n",
            "Data types of columns:\n",
            " recency              int64\n",
            "history_segment     object\n",
            "history            float64\n",
            "mens                 int64\n",
            "womens               int64\n",
            "zip_code            object\n",
            "newbie               int64\n",
            "channel             object\n",
            "segment             object\n",
            "visit                int64\n",
            "conversion           int64\n",
            "spend              float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzZGlqVYAGXD"
      },
      "source": [
        "**2.1 Use the function calc_uplift() from the practice session to calculate the current uplift of the campaign. Remeber to modify the function according to the need. (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap8p380oAGXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf1e84a-79e2-42e3-9707-d097ccb33f06"
      },
      "source": [
        "def calc_uplift(df):\n",
        "    \"\"\"\n",
        "    Calculate the uplift generated by the campaign.\n",
        "    \n",
        "    Parameters:\n",
        "    - df (pandas DataFrame): The dataset containing the campaign data.\n",
        "    \n",
        "    Returns:\n",
        "    - uplift (float): The uplift generated by the campaign.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Calculate the conversion rate for each group\n",
        "    control_conv_rate = df[df['segment'] == 'No E-Mail']['conversion'].mean()\n",
        "    mens_conv_rate = df[df['segment'] == 'Mens E-Mail']['conversion'].mean()\n",
        "    womens_conv_rate = df[df['segment'] == 'Womens E-Mail']['conversion'].mean()\n",
        "    \n",
        "    # Calculate the overall conversion rate\n",
        "    overall_conv_rate = df['conversion'].mean()\n",
        "    \n",
        "    # Calculate the uplift for each group\n",
        "    control_uplift = mens_uplift = womens_uplift = 0\n",
        "    if overall_conv_rate > 0:\n",
        "        control_uplift = (mens_conv_rate + womens_conv_rate - 2 * overall_conv_rate) / overall_conv_rate\n",
        "        mens_uplift = (mens_conv_rate - overall_conv_rate) / overall_conv_rate\n",
        "        womens_uplift = (womens_conv_rate - overall_conv_rate) / overall_conv_rate\n",
        "    \n",
        "    # Calculate the overall uplift\n",
        "    uplift = (df[df['segment'] == 'Mens E-Mail']['conversion'].sum() + df[df['segment'] == 'Womens E-Mail']['conversion'].sum()) / df['conversion'].sum() - 1\n",
        "    \n",
        "    # Print the results\n",
        "    print('Control conversion rate:', control_conv_rate)\n",
        "    print('Mens conversion rate:', mens_conv_rate)\n",
        "    print('Womens conversion rate:', womens_conv_rate)\n",
        "    print('Control uplift:', control_uplift)\n",
        "    print('Mens uplift:', mens_uplift)\n",
        "    print('Womens uplift:', womens_uplift)\n",
        "    print('Overall uplift:', uplift)\n",
        "    \n",
        "    return uplift\n",
        "\n",
        "uplift = calc_uplift(df)\n",
        "print('Current uplift:', uplift)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control conversion rate: 0.005726086548390125\n",
            "Mens conversion rate: 0.01253109306800582\n",
            "Womens conversion rate: 0.008837144059475383\n",
            "Control uplift: 0.3660331767453238\n",
            "Mens uplift: 0.387525876042167\n",
            "Womens uplift: -0.02149269929684335\n",
            "Overall uplift: -0.2110726643598616\n",
            "Current uplift: -0.2110726643598616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbjH40kbAGXD"
      },
      "source": [
        "**2.2 Create a new column named target_class. Split the customers in 4 categories:**\n",
        "\n",
        "1- Treatment Responders \n",
        "\n",
        "2- Treatment Non-Responders (sleeping dogs)\n",
        "\n",
        "3- Control Responders (sure things)\n",
        "\n",
        "4-Control Non-Responders(lost causes).\n",
        "\n",
        "**Label encode these categories and store the result for each customer in the column target_class (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCudxBkcAGXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "192cdc00-a262-4821-d3bf-d7eef947ab88"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# Create a copy of the original dataframe\n",
        "df_encoded = df.copy()\n",
        "\n",
        "# Encode the non-numeric columns using one-hot encoding\n",
        "non_numeric_cols = ['history_segment', 'zip_code', 'channel']\n",
        "ohe = OneHotEncoder()\n",
        "for col in non_numeric_cols:\n",
        "    encoded_col = ohe.fit_transform(df_encoded[col].values.reshape(-1,1)).toarray()\n",
        "    n_cols = encoded_col.shape[1]\n",
        "    for i in range(n_cols):\n",
        "        df_encoded[f\"{col}_{i}\"] = encoded_col[:, i]\n",
        "    df_encoded.drop(col, axis=1, inplace=True)\n",
        "\n",
        "# Create the target_class column\n",
        "df_encoded['target_class'] = ''\n",
        "\n",
        "# Define the boolean indexing conditions for each category\n",
        "treatment_responders = (df_encoded['segment'].isin(['Mens E-Mail', 'Womens E-Mail'])) & (df_encoded['conversion'] == 1)\n",
        "treatment_non_responders = (df_encoded['segment'].isin(['Mens E-Mail', 'Womens E-Mail'])) & (df_encoded['conversion'] == 0)\n",
        "control_responders = (df_encoded['segment'] == 'No E-Mail') & (df_encoded['conversion'] == 1)\n",
        "control_non_responders = (df_encoded['segment'] == 'No E-Mail') & (df_encoded['conversion'] == 0)\n",
        "\n",
        "# Fit and transform the categories to their encoded labels\n",
        "le = LabelEncoder()\n",
        "categories = ['Treatment Responders', 'Treatment Non-Responders', 'Control Responders', 'Control Non-Responders']\n",
        "le.fit(categories)\n",
        "\n",
        "# Label encode the categories and store the result in the target_class column\n",
        "df_encoded.loc[treatment_responders, 'target_class'] = le.transform(['Treatment Responders'])[0]\n",
        "df_encoded.loc[treatment_non_responders, 'target_class'] = le.transform(['Treatment Non-Responders'])[0]\n",
        "df_encoded.loc[control_responders, 'target_class'] = le.transform(['Control Responders'])[0]\n",
        "df_encoded.loc[control_non_responders, 'target_class'] = le.transform(['Control Non-Responders'])[0]\n",
        "\n",
        "# Print the unique values in the target_class column\n",
        "print('Unique values in target_class:', df_encoded['target_class'].unique())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in target_class: [2 0 3 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmzOWN_LAGXF"
      },
      "source": [
        "**2.3 Apply the necessary preprocessing to the data and split it into train and test set, using 80/20 ratio. Remember that you have to drop the columns that define the label and perform preprocessing. Build a model with your classifier of choice that will predict probabilities for the categories mentioned in 2.2. (1.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-41XdRBAGXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "622f126a-3f88-4874-a15e-abfed90a9e28"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Convert the target_class column to integer type\n",
        "df_encoded['target_class'] = df_encoded['target_class'].astype(int)\n",
        "\n",
        "# Drop columns that define the label\n",
        "X = df_encoded.drop(['conversion', 'segment', 'target_class'], axis=1)\n",
        "y = df_encoded['target_class']\n",
        "\n",
        "# Perform preprocessing\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Instantiate the classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for each class on the test data\n",
        "y_prob = rf.predict_proba(X_test)\n",
        "\n",
        "# Print the probabilities for each class\n",
        "print('Probabilities for each class:')\n",
        "for i, label in enumerate(le.classes_):\n",
        "    print(label, y_prob[:, i])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities for each class:\n",
            "Control Non-Responders [0.03 0.11 0.18 ... 0.05 0.09 0.5 ]\n",
            "Control Responders [0.   0.   0.   ... 0.   0.22 0.  ]\n",
            "Treatment Non-Responders [0.97 0.89 0.82 ... 0.95 0.02 0.5 ]\n",
            "Treatment Responders [0.   0.   0.   ... 0.   0.67 0.  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdoVNjw6AGXG"
      },
      "source": [
        "**2.4 Calculate the uplift score using probabilities for all customers and store the results to a new column in the dataframe (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx9PITUEAGXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace97215-fa15-451b-c3f8-0aba077667e9"
      },
      "source": [
        "# Calculate probabilities for each class on the entire data\n",
        "y_prob_all = rf.predict_proba(X)\n",
        "\n",
        "# Calculate expected outcome for each customer in treatment group\n",
        "df_encoded['treatment_prob'] = y_prob_all[:, 2] + y_prob_all[:, 3]\n",
        "\n",
        "# Calculate expected outcome for each customer in control group\n",
        "df_encoded['control_prob'] = y_prob_all[:, 1] + y_prob_all[:, 0]\n",
        "\n",
        "# Calculate uplift score for each customer\n",
        "df_encoded['uplift_score'] = df_encoded['treatment_prob'] - df_encoded['control_prob']\n",
        "\n",
        "# Visualize the uplift_score\n",
        "print(df_encoded['uplift_score'].head())\n",
        "print('=====')\n",
        "print(df_encoded['uplift_score'].describe())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    0.76\n",
            "1   -0.76\n",
            "2    0.84\n",
            "3    0.96\n",
            "4    0.72\n",
            "Name: uplift_score, dtype: float64\n",
            "=====\n",
            "count    64000.000000\n",
            "mean         0.334997\n",
            "std          0.581210\n",
            "min         -1.000000\n",
            "25%         -0.240000\n",
            "50%          0.520000\n",
            "75%          0.840000\n",
            "max          1.000000\n",
            "Name: uplift_score, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJGs1OFPAGXG"
      },
      "source": [
        "**2.5  Select the customers with High Uplift Score as below:**\n",
        "    \n",
        "**High Uplift Score:** Customers have uplift score > 3rd quantile\n",
        "\n",
        "**a. Calculate the ratio of the customers targeted with Womens e-mail that have high uplift score over the total customers who received emails featuring Womens merchandise. (0.5 points)**\n",
        "\n",
        "**b. Calculate the ratio of the customers targeted with Mens e-mail that have high uplift score over the total customers who received emails featuring Mens merchandise. (0.5 points)**\n",
        "\n",
        "\n",
        "**c.Which one of the campaigns would you say is more successful ? (0.5 points)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tICgdfgAGXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dfe2496-6433-431f-9c9f-8e624777a93c"
      },
      "source": [
        "# Calculate the 3rd quartile of uplift scores\n",
        "uplift_q3 = df_encoded['uplift_score'].quantile(0.75)\n",
        "\n",
        "# Select customers with high uplift score\n",
        "df_high_uplift = df_encoded[df_encoded['uplift_score'] > uplift_q3]\n",
        "\n",
        "# Calculate the ratio of customers with high uplift score for each campaign\n",
        "womens_total = df_encoded[df_encoded['segment'] == 'Womens E-Mail'].shape[0]\n",
        "womens_high_uplift = df_high_uplift[df_high_uplift['segment'] == 'Womens E-Mail'].shape[0]\n",
        "womens_high_uplift_ratio = womens_high_uplift / womens_total\n",
        "\n",
        "mens_total = df_encoded[df_encoded['segment'] == 'Mens E-Mail'].shape[0]\n",
        "mens_high_uplift = df_high_uplift[df_high_uplift['segment'] == 'Mens E-Mail'].shape[0]\n",
        "mens_high_uplift_ratio = mens_high_uplift / mens_total\n",
        "\n",
        "print('Ratio of customers with high uplift score for Womens E-Mail:', womens_high_uplift_ratio)\n",
        "print('Ratio of customers with high uplift score for Mens E-Mail:', mens_high_uplift_ratio)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratio of customers with high uplift score for Womens E-Mail: 0.34605133959882173\n",
            "Ratio of customers with high uplift score for Mens E-Mail: 0.3521847280236542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzQIPDlUAGXH"
      },
      "source": [
        "<font color='red'> **Answer C:** Based on the ratios calculated above, the uplift scores for both campaigns are very similar. The ratio of customers with high uplift scores is slightly higher for the Mens E-Mail campaign. However, based on this information alone, we cannot definitively say which campaign is more successful. Success can be defined in different ways, depending on the business objectives. If the campaign's primary goal is to maximize the number of customers with high uplift scores, then the Mens E-Mail campaign is more successful. On the other hand, if the goal is to maximize the overall revenue, we need to consider the conversion rates and average order value of the customers targeted in each campaign. Therefore, to determine which campaign is more successful, we need to analyze the conversion rates and average order value of the customers targeted in each campaign. We can then compare these metrics between the two campaigns to determine which campaign is more effective in generating revenue for the business."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5xdB9vxAGXH"
      },
      "source": [
        "**2.6 For customers in the segment named \"Womens e-mail\" with high uplift score calculate conversion uplift and revenue uplift. Compare it with the benchmark from excercise 2.1 and draw conclusions. (0.75 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KLtrYHwAGXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b231b07b-5fc2-4e82-ce83-3d8522713a24"
      },
      "source": [
        "def calc_uplift(df):\n",
        "    \"\"\"\n",
        "    Calculate the uplift generated by the campaign.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pandas DataFrame): The dataset containing the campaign data.\n",
        "\n",
        "    Returns:\n",
        "    - uplift (float): The uplift generated by the campaign.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the conversion rate for each group\n",
        "    control_conv_rate = df[df['segment'] == 'No E-Mail']['conversion'].mean()\n",
        "    mens_conv_rate = df[df['segment'] == 'Mens E-Mail']['conversion'].mean()\n",
        "    womens_conv_rate = df[df['segment'] == 'Womens E-Mail']['conversion'].mean()\n",
        "\n",
        "    # Calculate the overall conversion rate\n",
        "    overall_conv_rate = df['conversion'].mean()\n",
        "\n",
        "    # Calculate the uplift for each group\n",
        "    control_uplift = mens_uplift = womens_uplift = 0\n",
        "    if overall_conv_rate > 0:\n",
        "        control_uplift = (mens_conv_rate + womens_conv_rate - 2 * overall_conv_rate) / overall_conv_rate\n",
        "        mens_uplift = (mens_conv_rate - overall_conv_rate) / overall_conv_rate\n",
        "        womens_uplift = (womens_conv_rate - overall_conv_rate) / overall_conv_rate\n",
        "\n",
        "    # Calculate the overall uplift\n",
        "    uplift = (df[df['segment'] == 'Mens E-Mail']['conversion'].sum() + df[df['segment'] == 'Womens E-Mail']['conversion'].sum()) / df['conversion'].sum() - 1\n",
        "\n",
        "    # Calculate the uplift for women with high uplift score\n",
        "    df_womens_high_uplift = df[(df['segment'] == 'Womens E-Mail') & (df['uplift_score'] > df['uplift_score'].quantile(0.75))]\n",
        "    womens_high_uplift_conv_rate = df_womens_high_uplift['conversion'].mean()\n",
        "    womens_high_uplift_uplift = (womens_high_uplift_conv_rate - overall_conv_rate) / overall_conv_rate\n",
        "    womens_high_uplift_rev = womens_high_uplift_uplift * df_womens_high_uplift['spend'].sum()\n",
        "\n",
        "    # Print the results\n",
        "    print('Control conversion rate:', control_conv_rate)\n",
        "    print('Mens conversion rate:', mens_conv_rate)\n",
        "    print('Womens conversion rate:', womens_conv_rate)\n",
        "    print('Control uplift:', control_uplift)\n",
        "    print('Mens uplift:', mens_uplift)\n",
        "    print('Womens uplift:', womens_uplift)\n",
        "    print('Overall uplift:', uplift)\n",
        "    print('Womens high uplift conversion rate:', womens_high_uplift_conv_rate)\n",
        "    print('Womens high uplift uplift:', womens_high_uplift_uplift)\n",
        "    print('Womens high uplift revenue:', womens_high_uplift_rev)\n",
        "\n",
        "    return\n",
        "\n",
        "print('Overall campaign uplift:')\n",
        "calc_uplift(df_encoded)\n",
        "\n",
        "print('\\nUplift for Womens E-Mail with High Uplift Score:')\n",
        "calc_uplift(df_high_uplift[df_high_uplift['segment'] == 'Womens E-Mail'])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall campaign uplift:\n",
            "Control conversion rate: 0.005726086548390125\n",
            "Mens conversion rate: 0.01253109306800582\n",
            "Womens conversion rate: 0.008837144059475383\n",
            "Control uplift: 0.3660331767453238\n",
            "Mens uplift: 0.387525876042167\n",
            "Womens uplift: -0.02149269929684335\n",
            "Overall uplift: -0.2110726643598616\n",
            "Womens high uplift conversion rate: 0.011079583840021619\n",
            "Womens high uplift uplift: 0.22680513107505823\n",
            "Womens high uplift revenue: 2192.1441694823816\n",
            "\n",
            "Uplift for Womens E-Mail with High Uplift Score:\n",
            "Control conversion rate: nan\n",
            "Mens conversion rate: nan\n",
            "Womens conversion rate: 0.011079583840021619\n",
            "Control uplift: nan\n",
            "Mens uplift: nan\n",
            "Womens uplift: 0.0\n",
            "Overall uplift: 0.0\n",
            "Womens high uplift conversion rate: 0.004140786749482402\n",
            "Womens high uplift uplift: -0.6262687471595213\n",
            "Womens high uplift revenue: -83.87617330707468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81zo5gSsAGXI"
      },
      "source": [
        "<font color='red'> **Answer:** Looking at the results, we can conclude that sending a Women's e-mail to customers with high uplift score yields positive conversion and revenue uplifts. For the entire dataset, the uplift rates for the control and men's groups are higher than the women's group, meaning that sending no email or a men's email yields better results than a women's email. The overall campaign has a negative uplift, which means that sending the emails did not result in an overall increase in conversion rate. However, for customers in the Women's e-mail segment with high uplift scores, the conversion rate is significantly higher than the overall conversion rate, resulting in a positive uplift of 22.68%. Sending a Women's e-mail to customers with high uplift scores considerably increased this segment's conversion rate. The revenue uplift for this segment is also positive, resulting in a revenue increase of 2192.14. Therefore, sending a Women's e-mail to customers with high uplift scores is more successful than not sending an email or a Men's e-mail for this segment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFyyt8arAGXI"
      },
      "source": [
        "## How long did it take you to solve the homework?\n",
        "\n",
        "* Please answer as precisely as you can. It does not affect your points or grade in any way. It is okay, if it took 0.5 hours or 24 hours. The collected information will be used to improve future homeworks.\n",
        "\n",
        "<font color='red'> **Answer: 16 hours**</font>\n",
        "\n",
        "\n",
        "## What is the level of difficulty for this homework?\n",
        "you can put only number between $0:10$ ($0:$ easy, $10:$ difficult)\n",
        "\n",
        "<font color='red'> **Answer: 9**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6DX8HZHpLs_y"
      }
    }
  ]
}